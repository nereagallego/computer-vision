{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "# Medical Image Segmentation. Traditional vs Deep Learning methods.\n",
    "\n",
    "In this Practice, you will develop and train a convolutional neural network for brain tumour image segmentation\n",
    "and compare the performance with respect to traditional methods for image segmentation. \n",
    "\n",
    "When you train the network, it is recommended to use the GPU resources of your computer. \n",
    "This will help you to learn the \"know how\" of setting up a working Python environment on your computer.\n",
    "\n",
    "In the case of unavailable Nvidia hardware or problems with your Python environment you can use Google Colab.\n",
    "Please go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware accelerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this Practice.\n",
    "# However, if any other library is needed, please install it by yourself.\n",
    "import tarfile\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## Download the imaging dataset\n",
    "\n",
    "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save the storage and reduce the computational cost for this practice, we extract 2D image slices from T1-Gd contrast enhanced 3D brain volumes and downsample the images.\n",
    "\n",
    "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
    "\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mt93oQ8xZkE9",
    "outputId": "59284010-3c71-40b0-9578-ae25b5749e35"
   },
   "outputs": [],
   "source": [
    "# Dataset should be download\n",
    "\n",
    "# Unzip the '.tar.gz' file to the current directory\n",
    "datafile = tarfile.open('Task01_BrainTumour_2D.tar.gz')\n",
    "datafile.extractall()\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the imaging dataset\n",
    "\n",
    "Select a number of training and test images and visualize them in a grid to have an initial idea of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code ###\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('VisualizaciÃ³n de datos')\n",
    "img = np.asarray(Image.open('Task01_BrainTumour_2D/training_images/BRATS_001_z108.png'))\n",
    "axs[0,0].imshow(img)\n",
    "img = np.asarray(Image.open('Task01_BrainTumour_2D/training_images/BRATS_001_z124.png'))\n",
    "axs[0,1].imshow(img)\n",
    "img = np.asarray(Image.open('Task01_BrainTumour_2D/training_images/BRATS_001_z46.png'))\n",
    "axs[1,0].imshow(img)\n",
    "img = np.asarray(Image.open('Task01_BrainTumour_2D/training_images/BRATS_001_z62.png'))\n",
    "axs[1,1].imshow(img)\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xWGT3KaML-D"
   },
   "source": [
    "# Implement a dataset class\n",
    "\n",
    "It can read the imaging dataset and get items, pairs of images and label maps, as training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6p6wFZ3na5z9"
   },
   "outputs": [],
   "source": [
    "def normalise_intensity(image, thres_roi=1.0):\n",
    "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
    "    # ROI defines the image foreground\n",
    "    val_l = np.percentile(image, thres_roi)\n",
    "    roi = (image >= val_l)\n",
    "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
    "    eps = 1e-6\n",
    "    image2 = (image - mu) / (sigma + eps)\n",
    "    return image2\n",
    "\n",
    "\n",
    "class BrainImageSet(Dataset):\n",
    "    \"\"\" Brain image set \"\"\"\n",
    "    def __init__(self, image_path, label_path='', deploy=False):\n",
    "        \n",
    "        # Initialize self variables\n",
    "        ### Insert your code ###\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.deploy = deploy\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        ### End of your code ###\n",
    "        \n",
    "        image_names = sorted(os.listdir(image_path))\n",
    "        for image_name in image_names:\n",
    "            # Read the image. Use imageio.imread.\n",
    "            ### Insert your code ###\n",
    "            \n",
    "            image = imageio.imread('Task01_BrainTumour_2D/training_images/'+image_name)  ###code\n",
    "            \n",
    "            self.images += [image]\n",
    "\n",
    "            # Read the label map\n",
    "            if not self.deploy:\n",
    "                ### Insert your code ###\n",
    "                label = imageio.imread('Task01_BrainTumour_2D/training_labels/'+image_names)\n",
    "                self.labels += [label]\n",
    "                ### End of your code ###\n",
    "        \n",
    "\n",
    "    def __len__(self): # Number of images\n",
    "        ### Insert your code ###\n",
    "        return len(self.images)\n",
    "        ### End ofreturn len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get an image and perform intensity normalisation\n",
    "        # Dimension: XY\n",
    "        ### Insert your code ###\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        image = normalise_intensity(image)\n",
    "        ### End of your code ###\n",
    "        \n",
    "        # Get its label map\n",
    "        # Dimension: XY\n",
    "        ### Insert your code ###\n",
    "        label = self.labels[idx]\n",
    "        ### End of your code ###\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    \n",
    "    def get_random_batch(self, batch_size):\n",
    "        # Get a batch of paired images and label maps\n",
    "        # Dimension of images: NCXY\n",
    "        # Dimension of labels: NXY\n",
    "        images, labels = [], []\n",
    "\n",
    "        ### Insert your code ###\n",
    "        for i in range(batch_size):\n",
    "            idx = random.randint(0,len(self.images))\n",
    "            images += [self.images[idx]]\n",
    "            labels += [self.labels[idx]]\n",
    "        ### End of your code ###\n",
    "        \n",
    "        images = np.array( images )\n",
    "        print(images.shape)\n",
    "        \n",
    "        images = np.expand_dims(images, axis = 1) #NCXY dimension, with C = 1\n",
    "\n",
    "        labels = np.array( labels )\n",
    "\n",
    "        return images, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4ZpawDNmwu"
   },
   "source": [
    "# Build a U-net architecture\n",
    "\n",
    "You will implement a U-net architecture. If you are not familiar with U-net, please read this paper:\n",
    "\n",
    "[1] Olaf Ronneberger et al. [U-Net: Convolutional networks for biomedical image segmentation](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28). MICCAI, 2015.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMPmBZVGb1aI"
   },
   "outputs": [],
   "source": [
    "\"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "            \n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "           \n",
    "        \"\"\" U-net \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # BatchNorm: by default during training this layer keeps running estimates\n",
    "        # of its computed mean and variance, which are then used for normalization\n",
    "        # during evaluation.\n",
    "\n",
    "        # Encoder path\n",
    "        n = num_filter  # 16\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        n *= 2  # 32\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        n *= 2  # 64\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "            \n",
    "        n *= 2  # 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "           \n",
    "        # n *= 2  # 256\n",
    "        # n = int(n / 2)  # 64\n",
    "        # self.up3 = nn.ConvTranspose2d(n * 2, n, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        # self.conv_up3 = nn.Sequential(\n",
    "        #     nn.Conv2d(n * 2, n, kernel_size=3, padding=1),\n",
    "        #     nn.BatchNorm2d(n),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "        #     nn.BatchNorm2d(n),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        # n = int(n / 2)  # 32\n",
    "        # self.up2 = nn.ConvTranspose2d(n*2, n, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        # self.conv_up2 = nn.Sequential(\n",
    "        #     nn.Conv2d(n * 2, n, kernel_size=3, padding=1),\n",
    "        #     nn.BatchNorm2d(n),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "        #     nn.BatchNorm2d(n),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "        \n",
    "            \n",
    "        n = int(n / 2)  # 16\n",
    "        self.up1 = nn.ConvTranspose2d(n*2, n, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv_up1 = nn.Sequential(\n",
    "            nn.Conv2d(n * 2, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Output\n",
    "        self.out = nn.Conv2d(n, output_channel, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the convolutional operators defined above to build the U-net\n",
    "        # The encoder part is already done for you.\n",
    "        # You need to complete the decoder part.\n",
    "        \n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        conv1_skip = x\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        conv2_skip = x\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        conv3_skip = x\n",
    "\n",
    "        # x = self.conv4(x)\n",
    "        # conv4_skip = x\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        # x = self.up4(x)\n",
    "        # x = torch.cat([conv4_skip, x], dim=1)\n",
    "        # x = self.conv_up4(x)\n",
    "            \n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([conv3_skip, x], dim = 1)\n",
    "        x = self.conv_up3(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([conv2_skip, x], dim = 1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([conv1_skip, x], dim = 1)\n",
    "        x = self.conv_up1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcNWZS08d47P"
   },
   "source": [
    "# Train the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaGGkKQndIaR",
    "outputId": "fdf8f309-8c82-4e6c-94f5-c33bd34866d2"
   },
   "outputs": [],
   "source": [
    "# CUDA device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {0}'.format(device))\n",
    "\n",
    "# Build the model\n",
    "\"\"\"\n",
    "- 0: background\n",
    "- 1: edema\n",
    "- 2: non-enhancing tumour\n",
    "- 3: enhancing tumour\n",
    "\"\"\"\n",
    "num_class = 4\n",
    "\n",
    "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
    "model = model.to(device)\n",
    "params = list(model.parameters())\n",
    "\n",
    "summary(model,(1,128,128))\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Adam Optimizer\n",
    "### Insert your code ###\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "### End of your code ###\n",
    "\n",
    "# Segmentation loss. Criterion: Cross Entropy Loss.\n",
    "### Insert your code ###\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "### End of your code ###\n",
    "\n",
    "# Datasets\n",
    "train_set = BrainImageSet('Task01_BrainTumour_2D/training_images', 'Task01_BrainTumour_2D/training_labels')\n",
    "test_set = BrainImageSet('Task01_BrainTumour_2D/test_images', 'Task01_BrainTumour_2D/test_labels')\n",
    "\n",
    "# Train the model\n",
    "# Note: when you debug the model, you may reduce the number of iterations or batch size to save time.\n",
    "num_iter = 10000\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 16\n",
    "\n",
    "start = time.time()\n",
    "for it in range(1, 1 + num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # Get a random batch of images and labels\n",
    "    ### Insert your code ###\n",
    "    images, labels = train_set.get_random_batch(train_batch_size)\n",
    "    ### End of your code ###\n",
    "    \n",
    "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "    logits = model(images)\n",
    "    \n",
    "    # Note that optimizer.zero_grad() is equivalent to net.zero_grad() if it optimises all the net parameters.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Perform optimisation: compute the loss, backpropagation, and perform a step of your optimizer\n",
    "    ### Insert your code ###\n",
    "    loss = criterion(logits, labels)\n",
    "    ### End of your code ###\n",
    "\n",
    "    print('--- Iteration {0}: Training loss = {1:.4f}, {2:.4f} s ---'.format(it, loss.item(), time.time() - start_iter))\n",
    "\n",
    "    # Evaluate\n",
    "    if it % 10 == 0:\n",
    "        model.eval()\n",
    "        # Disabling gradient calculation during inference to reduce memory consumption\n",
    "        with torch.no_grad():\n",
    "            images, labels = test_set.get_random_batch(eval_batch_size)\n",
    "            images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "            images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            print('--- Iteration {0}: Test loss = {1:.4f} ---\\n'.format(it, loss.item()))\n",
    "\n",
    "    # Save the model\n",
    "    if it % 5000 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
    "        \n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yjxjGyb6yT"
   },
   "source": [
    "# Visualise the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czWxBFV2enU8",
    "outputId": "9c4a2708-d038-4572-f918-0c14f0c46ffc"
   },
   "outputs": [],
   "source": [
    "# Get a random batch of test images\n",
    "# Segment the images using the trained model\n",
    "images, labels = test_set.get_random_batch(5)\n",
    "images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
    "images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
    "model.eval()\n",
    "logits = model(images)\n",
    "prob = F.softmax(logits, dim=1)\n",
    "seg = torch.argmax(prob, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "id": "wZeLE0qZjd2j",
    "outputId": "425ffb36-68e1-41b0-8b6e-5ba9849d174f"
   },
   "outputs": [],
   "source": [
    "# Visualise the image, automated segmentation and manual segmentation\n",
    "plt.subplots(5, 3, figsize=(15, 16))\n",
    "\n",
    "### Insert your code ###\n",
    "[Insert your code here]\n",
    "### End of your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the segmentation results\n",
    "\n",
    "Use the Dice Similarity Coefficient (DSC) for the edema, non-enhancing tumour, enhancing tumour\n",
    "Show boxplots of the similarity distribution on your test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code ###\n",
    "[Insert your code here]\n",
    "### End of your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ0gincOMRXl"
   },
   "outputs": [],
   "source": [
    "## Investigating traditional methods\n",
    "\n",
    "Select three images with low, medium, and high DSC score and try to segment the labels with traditional methods\n",
    "of your choice. Explain your conclusions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code ###\n",
    "[Insert your code here]\n",
    "### End of your code ###"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0bb5b079ef3c3c7305ad9fc267617e01927ad1993e993abbe4a7f06194fdf24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
